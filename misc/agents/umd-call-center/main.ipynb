{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env.local\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .docx to text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AzureAI Document Intelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.doc_intelligence import (\n",
    "    AzureAIDocumentIntelligenceLoader,\n",
    ")\n",
    "import os\n",
    "AZURE_DOCUMENT_INTELLIGENCE_API_KEY = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_API_KEY\")\n",
    "def load_docs_adi(filepath: str):\n",
    "    adi = AzureAIDocumentIntelligenceLoader(\n",
    "        \"https://eastus.api.cognitive.microsoft.com\",\n",
    "        AZURE_DOCUMENT_INTELLIGENCE_API_KEY,\n",
    "        file_path=filepath,\n",
    "        api_model=\"prebuilt-read\",\n",
    "    )\n",
    "    docs = adi.load()\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "def load_docs_pypdf(file_path: str):\n",
    "    pypdf_loader = PyPDFLoader(\n",
    "        file_path = file_path,\n",
    "        password = None,\n",
    "        extract_images = True,\n",
    "        # headers = None\n",
    "        # extraction_mode = \"plain\",\n",
    "        # extraction_kwargs = None,\n",
    "    )\n",
    "    docs = pypdf_loader.load()\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zerox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "def load_docs_zerox(path:str):\n",
    "    with open(path, \"r\") as f:\n",
    "        data = f.read()\n",
    "    return [Document(page_content=data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "#file_path = os.path.join(current_dir, \"RA Duty Manual - Final Draft 2023-2024.pdf\")\n",
    "file_path = os.path.join(current_dir, \"./zerox/output.md\")\n",
    "\n",
    "docs = load_docs_zerox(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone.grpc import GRPCVector\n",
    "from pinecone.grpc.index_grpc import UpsertResponse\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_HOST = os.getenv(\"PINECONE_HOST\")\n",
    "PINECONE_NAMESPACE = \"umd-call-center\"\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "PC_INDEX_NAME = \"knowledge\"\n",
    "pc_index = pc.Index(PC_INDEX_NAME, host=PINECONE_HOST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def query_pc(vector: List[float]):\n",
    "    query_result = pc_index.query(\n",
    "        vector=vector,\n",
    "        namespace=PINECONE_NAMESPACE,\n",
    "        top_k=10,\n",
    "        #filter={\"knowledge_uuid\": {\"$in\": knowledge_uuids}},\n",
    "        include_metadata=True,\n",
    "        timeout=1,\n",
    "    )\n",
    "    return query_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Local Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "embedder = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\", api_key=OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "def split_by_semantics(content:str):\n",
    "    semantic_splitter = SemanticChunker(\n",
    "        embedder,\n",
    "        add_start_index=True,\n",
    "        sentence_split_regex=r\"(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)(?=\\s)\",\n",
    "    )\n",
    "    splits = semantic_splitter.split_documents([Document(page_content=content)])\n",
    "    start_index = 0\n",
    "    for i, split in enumerate(splits):\n",
    "        last_index = start_index + len(content) - 1\n",
    "        split.metadata[\"start_index\"] = start_index\n",
    "        start_index = last_index + 1\n",
    "    return splits\n",
    "\n",
    "def split_by_character(content:str):\n",
    "    recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=800, chunk_overlap=400, add_start_index=True\n",
    "    )\n",
    "    splits = recursive_splitter.split_documents([Document(page_content=content)])\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Test Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval relevence\n",
    "Are the documents that were retrieved relevent to the query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer Faithfulness\n",
    "Is the answer grounded in the documents?\n",
    "- This can measure hallucinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer Correctness\n",
    "Is the answer consistent with a reference answer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gen dataset giskard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "splits = []\n",
    "for doc in docs:\n",
    "    splits.extend(split_by_character(doc.page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8aa6cf10-812f-48d8-8437-7cb0de6a4243',\n",
       " 'be365dfb-f8c9-4b6f-a14b-c3966d0030f6',\n",
       " '122f53f0-5f27-41b5-9633-b2d95b1aa255',\n",
       " 'c7f7e036-cd31-4451-a069-6facce129fc4',\n",
       " '031777de-28ab-42bb-adfd-ee31b11d5d82',\n",
       " '846b9aea-9354-49f5-a9f2-aa49898d2611',\n",
       " '89e572f4-cedd-4344-9948-da49e8fd9c52',\n",
       " 'd7c99160-9bfe-4504-a202-f15ad1b0c917',\n",
       " '80e4da48-ed34-4ac0-8510-8f05df238c97',\n",
       " 'a476cfc0-a78f-404c-8924-c037aef868d5',\n",
       " 'a14f7877-7908-4a60-9637-8afafd922d91',\n",
       " 'dc483b9d-2599-486f-b49f-2d7f093b94a9',\n",
       " '7c551313-4487-436f-8bb5-8a94d78374b6',\n",
       " '11ab8557-09ce-4c6d-8529-c091effd5f35',\n",
       " 'aef5caba-f69f-498e-a2ec-a16d67766363',\n",
       " 'c3f3d7e6-64c4-4ffd-8720-f33ee477c62f',\n",
       " '43b90a1e-6879-4ce9-8b47-4fadc62c33d0',\n",
       " 'be12fb19-56fe-4e73-958c-90e6ba39cbce',\n",
       " '1410d79f-43a5-44e1-ab00-477d7e48fc6e',\n",
       " '98d9c228-4ba5-4dfb-a651-324e69a503c2',\n",
       " '24ebf26d-f6d4-4207-b58c-6797e6650761',\n",
       " '3bb3986d-b857-4ba5-89b3-b376e2e66f93',\n",
       " 'e387d3e5-f08c-4591-858f-b3769ea6196e',\n",
       " '90972e69-6e18-4c63-9a08-8c1ef86881ed',\n",
       " 'd715e570-b012-4362-a494-ae8bbe2205e5',\n",
       " 'ac25dc1b-178d-4d26-a1e2-102722a7961a',\n",
       " 'c0edb0c9-15fe-4da8-a473-ffa6f569a3d6',\n",
       " '2c09b98c-4fc2-4088-9c63-790f76027bfd',\n",
       " '1e37d870-72f3-4fa8-91dd-92864a035010',\n",
       " 'd4a3662a-be1c-4856-a6a3-fa01f88b9338',\n",
       " '12ee2d53-7e1b-4494-b67f-bac263de2ea6',\n",
       " '589bcd63-2fd0-466d-93e9-5929f05331ec',\n",
       " 'cee6e76a-f8d9-4af7-a262-54e54b581950',\n",
       " '56637553-bed4-49a7-a21d-9906dbd4a73b',\n",
       " 'db43135e-67a7-43d0-9a14-a1ed9d5e5fa8',\n",
       " '4161c19b-4e94-44e2-b8ba-62746357849b',\n",
       " '9df6666f-b3ec-4b50-9d5b-394d0a4a307b',\n",
       " '12c3743d-810a-4fd1-af84-3fb8babf4d4f',\n",
       " 'a9ae3d35-0522-4001-81e7-65d83c93939e',\n",
       " '95e7dbc1-53d8-4e25-855c-5f0e53031d8d',\n",
       " '35d2d650-2f0d-4f29-bf96-158941abaf19',\n",
       " 'fa6aada9-db19-4fca-8ed7-d8cd492f4897',\n",
       " 'c51cabf4-d6be-45b4-b9ad-ebd36e2d85ae',\n",
       " 'cc5bd9cb-6bdd-481f-a1bc-db06ccda0581',\n",
       " '0dd044e3-2956-44bf-a138-b03cb2547731',\n",
       " 'e5574bf0-676c-4a75-bd9d-72eb2b3d62e1',\n",
       " 'da044576-7e69-462b-b226-161e4c64c77d',\n",
       " '354cf79a-0abf-464a-88eb-4721c2586461',\n",
       " '16e2fa10-cf13-4f94-9471-d5fd364bfb89',\n",
       " '6b8901ee-8b24-4aa0-b52e-4b6af3a0be54',\n",
       " 'feaa73fd-58a6-4f29-a923-004cbcbe685e',\n",
       " '6215c080-2ecb-4275-8148-11302aa4880b',\n",
       " '4b93404b-3a00-4be0-a042-0854e21b4b4c',\n",
       " '3043b449-2966-4b8c-8853-2b1f0ea5e94a',\n",
       " '27082dd5-2790-4584-bfdc-73591ac55710',\n",
       " '900b354b-9a05-4815-86db-0441792056f5',\n",
       " 'f41bc8de-6c2a-411d-985a-c12bc6ded9cf',\n",
       " 'dd129d05-c947-493c-a8f6-477fcf08f45a',\n",
       " '6d1d6e36-e4b1-4123-8642-be6ba360a5c3',\n",
       " '83ac75b4-86f4-41d2-9060-dd57fad7badc',\n",
       " '28f0729e-01ce-45ac-8a44-9955a3ff56ec',\n",
       " '49907f9a-aedb-4ad7-9485-8dfa8697261b',\n",
       " '4b7ce9f2-4fc3-404a-ab1c-10769beabd6a',\n",
       " 'e0735b9c-d38e-40dd-84db-d3d39f437046',\n",
       " '5e16e2a8-ff93-4268-919f-70fe0d4c0277',\n",
       " '0f9b9381-0583-402d-9925-e71b3b3f4e50',\n",
       " '3a4e1ce4-1a28-4c48-ba93-7698281b4d91',\n",
       " '0386be8f-f973-4b11-94e2-e24a2016c8bd',\n",
       " '71bd8a33-c9e7-48d3-82cf-9e77a2def30a',\n",
       " '96b994f4-dc56-4574-9711-8aab98ffa673',\n",
       " 'b0b365f7-a2f4-454d-a4f8-e60d3f437f75',\n",
       " '9b931cf5-21df-4496-98da-69d98867b5a5',\n",
       " 'b8d5ec7b-1575-4229-a586-e69ee57d254b',\n",
       " 'b2e5ff6d-d057-493f-99e6-7c133c2ec0f6',\n",
       " '5c723945-e483-4890-846e-89015beb0717',\n",
       " '0e0f2cd4-7f44-4099-ba6d-3d967576499d',\n",
       " 'c7998948-909f-4186-ae88-a4413c5c20a4',\n",
       " 'bbc676dc-deab-40b5-b029-6cc13012e866',\n",
       " 'fd643d59-d39c-47fd-8fcf-9b90de28e523',\n",
       " 'c1eb03ea-5aff-41e1-b7d4-7790a2885234',\n",
       " 'd5daf102-c0b2-4670-a900-7c78521af5db',\n",
       " 'e1f7fca8-0793-45c5-a64c-3770ec0c7148',\n",
       " '27ee52ff-e99b-423d-b424-abd807c6092e',\n",
       " '65b22488-c44f-42aa-b509-f142b9c6b54a',\n",
       " 'a58c29a6-d2f4-4b8b-9c0f-130d4ee48a34',\n",
       " '9c00dc11-693f-44cb-b41c-7c2e382a7cc1',\n",
       " '4a210805-d22a-4cab-83cc-2effe1a93cb1',\n",
       " '73f7a526-798e-49c7-9325-db1b095776b2',\n",
       " '272bdb4b-7d47-4019-8d3a-859d43510ac4',\n",
       " '7f9b9f8b-c934-447b-9a43-c5c02cda3287',\n",
       " '90539c4b-7d05-43d6-9a5c-fc0d76381392',\n",
       " '1c3752fd-d3f5-4304-bf2f-648b5b3225b0',\n",
       " '26c101e2-262e-4d2e-bdd9-848c70dbfa48',\n",
       " '36dd30ca-a0f5-4f95-b005-70bb1e8774ad',\n",
       " '80cc5d0c-3c46-470e-9a55-8dd477f8df98',\n",
       " '2f7f1f65-8ed2-442f-8069-a18c29f7a2b4',\n",
       " '5531ffa1-606b-4a08-99af-d685ff3a93f2',\n",
       " '1bef2a3b-5c12-4b89-bbd4-f7e699d5fe6f',\n",
       " '5cc10cf9-c0e9-4486-8145-bddfe3d342a8',\n",
       " '39b46110-5cdd-47f7-929d-b967b7a3d96d',\n",
       " 'caaf4284-3ad3-46cc-a745-e75118ead88e',\n",
       " '34c11ba6-f480-46ea-8ed1-498cd6cdcfb9',\n",
       " '11754067-8dea-4b38-aa47-e3ac0250930b',\n",
       " 'd1015298-253f-453d-bf98-7544c4aba2d2',\n",
       " 'b9361672-a8f4-49b4-b58b-3348796a840f',\n",
       " '7302610f-f384-43d9-a4ec-667beae06147',\n",
       " '4907a779-d2dd-47ae-8baa-1c72e13caf58',\n",
       " '21ce7ce2-7e66-43b8-a97d-0fb0070256fa',\n",
       " '98b8edd8-0add-425f-9ca1-be1a071bc53b',\n",
       " '4e69dcdd-636d-48b0-94ed-585d8742cb7a',\n",
       " 'f9d63dcf-3304-4a7a-a6c9-9017da4d48ff',\n",
       " '10b18f2b-36b6-4e2d-b3d9-61d8d40374b8',\n",
       " 'a751455b-6266-4141-a420-69763397ed32',\n",
       " 'f0fdfd41-80aa-4d73-853f-d7848137c6f4',\n",
       " '0476b6f1-cfaf-4052-8059-4a5cac6a49bb',\n",
       " 'cb32ecf6-8368-4b06-bddf-f119a4baa1c3',\n",
       " 'bae640c8-da79-47be-86ba-0d53619c967e',\n",
       " '077ec3a0-4abe-4e77-9fa7-aba657579dbd',\n",
       " '0778a1cc-700d-4cf9-9217-6db58a19ae24',\n",
       " '15b5f229-a9c1-4a54-a09d-ea0dbde917c0',\n",
       " '2694d024-5bb0-47ab-aafb-8efef2adfc6c',\n",
       " 'b4b39c25-c425-47fd-83fe-3d079c17e9f2',\n",
       " '5f24b996-d2bf-46cc-a04e-f37d8d942083',\n",
       " 'f735a0f2-cd79-485d-97a1-b2508e887c48',\n",
       " '44ef7c98-9bc6-4fb1-b3a1-9ae4ad27615e',\n",
       " 'b97c7f28-3eec-43ee-93d0-f08c693c3bcd',\n",
       " '2a4f47e9-0784-4db1-b822-8dc30e70e1b4',\n",
       " 'b30975e9-7f74-4a1c-8d0d-4720c61e0e1a',\n",
       " '98997740-0e39-410c-8d6a-b74012710165',\n",
       " 'be7dcb90-7d3c-4905-84b0-31b5ce32cf47',\n",
       " '478cedc7-3019-481c-b1b8-d9111cd846bc',\n",
       " '3779b8f5-d312-4fbf-8f5b-006c39ffc441',\n",
       " 'e4d16d98-710f-4e13-86f9-6425ac19dab9',\n",
       " 'a05ae339-e8aa-4c88-9819-ba825ea39603',\n",
       " '0cb537d5-43aa-4dc7-a87c-cc53934f71b6',\n",
       " 'd5bbdaef-29c6-4968-bba3-bcc88638cd6d',\n",
       " '5c8d823a-4ebb-4dc0-b934-967a855a348e',\n",
       " '4aa08043-4c19-4361-bbec-db6b13cda348',\n",
       " '08a14354-856e-4296-ac71-537d2dea4451',\n",
       " '6cab853d-814b-4797-90e3-38a8a2bbe7b4',\n",
       " 'c214b6a8-0c66-44cd-abf5-2ab5f7272ad8',\n",
       " 'bb1845aa-26e6-45f0-9b50-baca3e795495',\n",
       " '4fdf278c-bacd-44fb-93c8-6c8889712884',\n",
       " 'bd16cdb6-dae1-4a7f-bfd5-2feae2f5fe4c',\n",
       " '6eed5f98-2718-4bd0-bd74-fe95808eae16',\n",
       " '0968a766-a008-46ef-a187-0a669ccde107',\n",
       " '0617827d-4159-4f3e-b8f2-d9912165558d',\n",
       " '3ffbe1e3-efcc-405d-8e3e-e4302a7a6945',\n",
       " '4fbeb163-dad4-47ca-be13-a953cfda33c8',\n",
       " 'e76362e5-ec51-4dd8-bdc5-3f7cb2ff7e9e',\n",
       " '1c0e7f1e-dc95-4c9e-9e36-c5c70e63fed2',\n",
       " '94bdbad7-f788-420a-870e-945448ff022d',\n",
       " '77be847c-9b3f-4382-8033-6ac914c02b91',\n",
       " '54b9295c-4be4-42d4-a6c2-296112a667a0',\n",
       " 'e38ab827-b481-47aa-a37c-afdbac09a3ee',\n",
       " 'daec1bb6-b602-4f46-b7a7-914135adfa21',\n",
       " '706bbe4a-3e7b-458a-af76-1bcd88055623',\n",
       " '5259c2fe-be9c-43d1-a157-4128e24d8723',\n",
       " 'd5c245b5-c9b2-4e1c-ab17-caa0275e915b',\n",
       " '6981c14e-a1f2-4209-a296-114d1351eb03',\n",
       " '050e1db0-8c2e-40b5-bf2d-b1aff550f9e2',\n",
       " 'e38bd50e-21c1-43e7-bf50-69d885076543',\n",
       " '251b5c9a-b49f-4397-834f-836cd293e825',\n",
       " 'f479577e-6567-4df6-aa60-45fdec7afb31',\n",
       " '858d4320-2488-4d40-8a6f-04c7730779a3',\n",
       " '41d76ad9-532c-4c6f-9446-9582fc4bd338',\n",
       " 'a73c7c7a-b615-4272-ac60-2e6acd0b0036',\n",
       " '591eefe1-ea57-47b3-a2a9-2ecf3c37c56e',\n",
       " '05ae09c8-eb21-4e07-83a2-5f53d2c01b3c',\n",
       " '42c5c961-dc8f-43c9-9207-14601490ea3c',\n",
       " 'fe3af00a-37e8-4ed8-ac7a-b967602fee85',\n",
       " '5bd674a9-4e1d-478c-a32e-e836c31c33e9',\n",
       " '8d3fb8e5-3833-4995-8a05-46be73ac0a73',\n",
       " '66a7c3bc-0adc-43cf-b9a0-39be31a0786d',\n",
       " 'fd94217c-28fe-414e-95f2-d41a18b019a3',\n",
       " '5c017c9f-0727-4301-9a9e-6b5de74a4e86',\n",
       " '32dfe6ee-7c1d-45a9-b18c-4ca819b8661e',\n",
       " '92fe99b5-4239-4f71-9f66-ca7ed851f5d9',\n",
       " '3c5ece53-a173-4752-84a1-c063184da782',\n",
       " '40425d8c-80f3-4ee4-85f7-c1e3353f219b',\n",
       " '35e60844-8b39-40ae-930e-edf233c90ee7',\n",
       " '191efac2-9b8c-4434-937d-d8481c64dc83',\n",
       " '7e000675-093e-4ec6-9fa4-0f25891a60fc',\n",
       " '6d6e9429-aaf1-448d-a689-bd9832dffdc2',\n",
       " 'f5beb811-aa60-40f8-a7d8-3fe7fef1925f',\n",
       " '415e464a-8e32-43f6-9141-ab863fe4d178',\n",
       " '295d71f3-b2a5-40dc-97c9-3daf797b37e9',\n",
       " '3d185142-70d0-4785-8238-dfecab56fd4c',\n",
       " '13c54033-cd4a-43f7-95d5-087d36bdba00',\n",
       " '13ee1a22-a5ec-4252-8cb0-cb9047e07dc7',\n",
       " '73830eb7-fb78-436f-a09d-5074dbe3cd88',\n",
       " '68c579fe-0419-41bf-98f5-d9f80506d37b',\n",
       " '44eb6ff4-f1c7-4e28-b205-fdcd38404f71',\n",
       " 'd8d4ed23-35a4-4247-8c0c-20ae9476e4a8',\n",
       " 'c2235e77-f7c6-4590-86f2-e2038d68ce74',\n",
       " '22ed3970-9121-4574-a0fc-5f9bfbb9e85d',\n",
       " '6b492189-97b7-4167-8932-544ba3114042',\n",
       " '4b81d470-f0cb-44f1-9935-91a137c1080f',\n",
       " '9377e5e5-e936-4f46-9f9d-e1431cfb1aae',\n",
       " '424c88d6-02e7-4e0c-a234-460b93386a68',\n",
       " 'c8849666-a39f-4934-8f9a-d89f2d1c8e09',\n",
       " '3669b173-4543-405f-a261-70df5a19b576',\n",
       " '0c762382-1cd2-4c4f-85ab-146cc6257d26',\n",
       " 'e450b330-363d-46b7-a890-2960df26513a',\n",
       " '3b305337-3d58-4509-a5e3-7a66a6d0d66e',\n",
       " '26d144d5-d037-4cd3-b169-56e9500ecae3',\n",
       " 'df9b0c56-ced3-484a-a4ee-7c5b1099e246',\n",
       " 'fff281da-0e67-4807-aa9d-6a73730176ca',\n",
       " '40225786-8121-461d-b13c-3c2704e6aeef',\n",
       " '58873b88-1b6c-4a8e-8a28-bd4c225bf516',\n",
       " '48af7d4e-5caa-4a69-b081-3f004d0dafe9',\n",
       " '0c96db62-ef26-434e-b55a-de33c2718516',\n",
       " '1b92cacc-68ea-4e5b-916e-db9bb5e14d78',\n",
       " 'f8a8cbc4-96b5-47ec-9191-d05e1b688f38',\n",
       " 'db8dab4c-4a07-47f3-b43c-d0309b1d90ab',\n",
       " 'f7fd6c7c-5753-42f7-8204-5064f30788e7',\n",
       " 'f7600650-a681-409c-b231-6ba71a2b8249',\n",
       " '1cc389d1-3ec5-4e2a-8e10-1242d8cf305e',\n",
       " '5c7ce6b6-0d11-4272-b5da-ae99a5f79926',\n",
       " 'd2978bf7-c5c8-4611-a681-ae519fbd6872',\n",
       " 'dea182f6-0427-429f-b697-cd3dfbf58be3',\n",
       " 'd5f85a9f-beb2-444e-b81e-66c0c4d1613f',\n",
       " '64ba167d-3f48-4bac-9202-5e095cfdb7c3',\n",
       " '28ddd7f5-177c-499b-9965-3fe042e39500',\n",
       " 'bbfd15aa-c491-4784-9b8d-2eac03fe95d3',\n",
       " '8b710a28-de20-44d5-b9aa-01ede92da0b1',\n",
       " '2a71cbe1-1ac8-434d-bbdc-3fbd4e0c39ff',\n",
       " 'b39cfff6-52a5-4da5-b7ee-1d2542083d68',\n",
       " 'cc0b5c6b-065e-4ce9-a0a6-9ca82edb8962',\n",
       " '7bdc13f4-b73c-45e7-b5ce-8b1263425b75',\n",
       " '3fa68841-5d03-4f1d-8b98-04f11c963227',\n",
       " 'b494027f-b7bd-4cab-8170-b22c8eea447e',\n",
       " '16714810-da8e-4cc9-9868-1994b8e4d503',\n",
       " '605f6135-fc83-47b9-bfd2-390d11134083',\n",
       " '3b975a92-8c34-4141-ae14-963af1f7f428',\n",
       " '2f60d556-780f-406d-a7d3-84ad0856fdbe',\n",
       " '63761458-8a47-4b1f-b1ff-872e29deb60b',\n",
       " '9a61f41b-d54c-4f09-9198-e2f83f7b559b',\n",
       " 'f1be60b6-a4da-42fb-9274-714946617498',\n",
       " '64caab50-ac6f-46c6-b9cd-d4ac86ef5e92']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store = InMemoryVectorStore(OpenAIEmbeddings(model=\"text-embedding-3-large\"))\n",
    "vector_store.add_documents(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.dump(\"vector_store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from giskard.rag import KnowledgeBase\n",
    "knowledge_base_df = pd.DataFrame([i.page_content for i in splits], columns=[\"text\"])\n",
    "knowledge_base = KnowledgeBase(knowledge_base_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = RAGReport.load(\"reports_testset250/p1-gpt_4o_mini-splits_character-max_marginal_relevance-top5-zerox-tester_gpt-4o-mini\")\n",
    "knowledge_base = report._knowledge_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import giskard\n",
    "from giskard.llm.client.openai import OpenAIClient\n",
    "\n",
    "giskard.llm.set_llm_api(\"openai\")\n",
    "oc = OpenAIClient(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Optional, Sequence, Union\n",
    "from giskard.llm.client import LLMClient, ChatMessage\n",
    "import openai\n",
    "from openai.types.chat.completion_create_params import ResponseFormatJSONObject, ResponseFormatText\n",
    "\n",
    "class O1PreviewClient(LLMClient):\n",
    "    def complete(self, messages: Sequence[ChatMessage], temperature: float = 1, max_tokens: Union[Optional[int], Any] = None, caller_id: str | None = None, seed: int | None = None, format=None) -> ChatMessage:\n",
    "        messages_openai = []\n",
    "        for message in messages:\n",
    "            role = message.role\n",
    "            if message.role != \"user\" or message.role != \"assistant\":\n",
    "                role = \"user\"\n",
    "            messages_openai.append({\"role\": role, \"content\": message.content})\n",
    "            \n",
    "        if format is not None and \"json\" in format:\n",
    "            rformat: ResponseFormatJSONObject = {\"type\": \"json_object\"}\n",
    "        else:\n",
    "            rformat: ResponseFormatText = {\"type\": \"text\"}\n",
    "\n",
    "        if max_tokens is None:\n",
    "            response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
    "        else:\n",
    "            response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1, max_tokens=max_tokens, seed=seed, response_format=rformat)\n",
    "            \n",
    "        cm = ChatMessage(role=response.choices[0].message.role, content=response.choices[0].message.content)\n",
    "        return cm\n",
    "    \n",
    "o1preview= O1PreviewClient()\n",
    "giskard.llm.set_default_client(o1preview)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating questions:  45%|████▌     | 45/100 [24:33<31:26, 34.30s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-27 23:06:20,995 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:06:20,997 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:06:22,677 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:06:22,678 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:06:24,383 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:06:24,385 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:06:25,938 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:06:25,939 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:06:27,698 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:06:27,699 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:06:29,490 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:06:29,491 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:06:31,046 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:06:31,048 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:06:32,553 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:06:32,555 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:06:34,199 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:06:34,200 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:06:35,755 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:06:35,758 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:06:37,286 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:06:37,288 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:06:38,983 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:06:38,984 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:06:40,574 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:06:40,575 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:06:42,186 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:06:42,188 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:06:43,784 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:06:43,785 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:06:45,354 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:06:45,355 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:06:46,989 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:06:46,990 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:06:48,672 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:06:48,673 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:06:50,309 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:06:50,311 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:06:52,140 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:06:52,141 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:06:53,867 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:06:53,868 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:06:55,811 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:06:55,813 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:06:57,407 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:06:57,408 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:06:59,112 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:06:59,114 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/double_questions.py\", line 105, in generate_single_question\n",
      "    linked_questions = self._llm_complete(\n",
      "                       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:07:00,750 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:07:00,752 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/double_questions.py\", line 105, in generate_single_question\n",
      "    linked_questions = self._llm_complete(\n",
      "                       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:07:02,428 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:07:02,432 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/double_questions.py\", line 105, in generate_single_question\n",
      "    linked_questions = self._llm_complete(\n",
      "                       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:07:04,126 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:07:04,128 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/double_questions.py\", line 105, in generate_single_question\n",
      "    linked_questions = self._llm_complete(\n",
      "                       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:07:05,670 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:07:05,671 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/double_questions.py\", line 105, in generate_single_question\n",
      "    linked_questions = self._llm_complete(\n",
      "                       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:07:07,370 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:07:07,371 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/double_questions.py\", line 105, in generate_single_question\n",
      "    linked_questions = self._llm_complete(\n",
      "                       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:07:08,847 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:07:08,849 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/double_questions.py\", line 105, in generate_single_question\n",
      "    linked_questions = self._llm_complete(\n",
      "                       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:07:10,464 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:07:10,465 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/double_questions.py\", line 105, in generate_single_question\n",
      "    linked_questions = self._llm_complete(\n",
      "                       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:07:12,133 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:07:12,135 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/double_questions.py\", line 105, in generate_single_question\n",
      "    linked_questions = self._llm_complete(\n",
      "                       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:07:13,713 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:07:13,714 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/double_questions.py\", line 105, in generate_single_question\n",
      "    linked_questions = self._llm_complete(\n",
      "                       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:07:15,488 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:07:15,491 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/double_questions.py\", line 105, in generate_single_question\n",
      "    linked_questions = self._llm_complete(\n",
      "                       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:07:17,033 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:07:17,034 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/double_questions.py\", line 105, in generate_single_question\n",
      "    linked_questions = self._llm_complete(\n",
      "                       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:07:18,631 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:07:18,633 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/double_questions.py\", line 105, in generate_single_question\n",
      "    linked_questions = self._llm_complete(\n",
      "                       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:07:20,285 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:07:20,286 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/double_questions.py\", line 105, in generate_single_question\n",
      "    linked_questions = self._llm_complete(\n",
      "                       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:07:22,107 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:07:22,108 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/double_questions.py\", line 105, in generate_single_question\n",
      "    linked_questions = self._llm_complete(\n",
      "                       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:07:23,677 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:07:23,679 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/double_questions.py\", line 105, in generate_single_question\n",
      "    linked_questions = self._llm_complete(\n",
      "                       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:07:25,387 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:07:25,388 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:07:27,146 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:07:27,148 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:07:28,742 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:07:28,745 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:07:30,373 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:07:30,374 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:07:31,933 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:07:31,934 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:07:33,469 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:07:33,470 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:07:35,028 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:07:35,032 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:07:36,785 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:07:36,786 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:07:38,619 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:07:38,620 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:07:40,150 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:07:40,151 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:07:41,810 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:07:41,811 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:07:43,434 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:07:43,435 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:07:45,092 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:07:45,094 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:07:46,666 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:07:46,667 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:07:48,388 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:07:48,389 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "2024-10-27 23:07:49,941 pid:49470 MainThread giskard.rag  ERROR    Encountered error in question generation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}. Skipping.\n",
      "2024-10-27 23:07:49,942 pid:49470 MainThread giskard.rag  ERROR    Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 57, in generate_questions\n",
      "    yield self.generate_single_question(knowledge_base, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/simple_questions.py\", line 96, in generate_single_question\n",
      "    generated_qa = self._llm_complete(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/question_generators/base.py\", line 42, in _llm_complete\n",
      "    out = self._llm_client.complete(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/gmwh2xtx0x1gxb7br9zgfpf00000gn/T/ipykernel_49470/438074895.py\", line 21, in complete\n",
      "    response = openai.chat.completions.create(messages=messages_openai, model=\"o1-preview\", temperature=1,seed=seed, response_format=rformat)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 815, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating questions:  45%|████▌     | 45/100 [26:04<31:52, 34.77s/it]\n"
     ]
    }
   ],
   "source": [
    "from giskard.rag import generate_testset\n",
    "\n",
    "testset = generate_testset(\n",
    "    knowledge_base,\n",
    "    num_questions=100,\n",
    "    language='en',  \n",
    "    agent_description=\"A support agent for the University of Maryland's call center.\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.to_pandas().to_excel(\"testset45-o1preview.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.save(\"testset45-o1preview.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from giskard.rag import QATestset\n",
    "testset = QATestset.load(\"testset250.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>reference_context</th>\n",
       "      <th>conversation_history</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f7688518-56c0-42b6-ac14-a3c83992a93d</th>\n",
       "      <td>What is the purpose of a Fire Watch?</td>\n",
       "      <td>A Fire Watch is an hourly foot patrol conducte...</td>\n",
       "      <td>Document 129: # Resources:\\n- **After a Fire**...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'simple', 'seed_document_id'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa5a916d-be2a-43bd-beee-3d778333d784</th>\n",
       "      <td>What is the primary focus of the Resident Dire...</td>\n",
       "      <td>The RD's primary focus must be the ability to ...</td>\n",
       "      <td>Document 16: Purpose: Being accessible to stud...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'simple', 'seed_document_id'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d58efa9b-2a56-4211-969b-c2d4605b8608</th>\n",
       "      <td>What should an RA do when a resident requires ...</td>\n",
       "      <td>The RA should contact UMPD at 301-405-3333 and...</td>\n",
       "      <td>Document 108: Procedure:  \\n1. When a resident...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'simple', 'seed_document_id'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9c433729-bb55-4cac-92f2-00903434fa28</th>\n",
       "      <td>What should a student do if they want to refus...</td>\n",
       "      <td>In non-emergencies, students may choose to ref...</td>\n",
       "      <td>Document 109: 2. Date of birth (if under 18, n...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'simple', 'seed_document_id'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0caee60d-567c-4f74-b0e0-aa4efe189ead</th>\n",
       "      <td>What should Fire Watch staff do with the Fire ...</td>\n",
       "      <td>Fire Watch staff must update the Log sheet eac...</td>\n",
       "      <td>Document 132: 2. Receive a Fire Watch Log shee...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'simple', 'seed_document_id'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                               question  \\\n",
       "id                                                                                        \n",
       "f7688518-56c0-42b6-ac14-a3c83992a93d               What is the purpose of a Fire Watch?   \n",
       "aa5a916d-be2a-43bd-beee-3d778333d784  What is the primary focus of the Resident Dire...   \n",
       "d58efa9b-2a56-4211-969b-c2d4605b8608  What should an RA do when a resident requires ...   \n",
       "9c433729-bb55-4cac-92f2-00903434fa28  What should a student do if they want to refus...   \n",
       "0caee60d-567c-4f74-b0e0-aa4efe189ead  What should Fire Watch staff do with the Fire ...   \n",
       "\n",
       "                                                                       reference_answer  \\\n",
       "id                                                                                        \n",
       "f7688518-56c0-42b6-ac14-a3c83992a93d  A Fire Watch is an hourly foot patrol conducte...   \n",
       "aa5a916d-be2a-43bd-beee-3d778333d784  The RD's primary focus must be the ability to ...   \n",
       "d58efa9b-2a56-4211-969b-c2d4605b8608  The RA should contact UMPD at 301-405-3333 and...   \n",
       "9c433729-bb55-4cac-92f2-00903434fa28  In non-emergencies, students may choose to ref...   \n",
       "0caee60d-567c-4f74-b0e0-aa4efe189ead  Fire Watch staff must update the Log sheet eac...   \n",
       "\n",
       "                                                                      reference_context  \\\n",
       "id                                                                                        \n",
       "f7688518-56c0-42b6-ac14-a3c83992a93d  Document 129: # Resources:\\n- **After a Fire**...   \n",
       "aa5a916d-be2a-43bd-beee-3d778333d784  Document 16: Purpose: Being accessible to stud...   \n",
       "d58efa9b-2a56-4211-969b-c2d4605b8608  Document 108: Procedure:  \\n1. When a resident...   \n",
       "9c433729-bb55-4cac-92f2-00903434fa28  Document 109: 2. Date of birth (if under 18, n...   \n",
       "0caee60d-567c-4f74-b0e0-aa4efe189ead  Document 132: 2. Receive a Fire Watch Log shee...   \n",
       "\n",
       "                                     conversation_history  \\\n",
       "id                                                          \n",
       "f7688518-56c0-42b6-ac14-a3c83992a93d                   []   \n",
       "aa5a916d-be2a-43bd-beee-3d778333d784                   []   \n",
       "d58efa9b-2a56-4211-969b-c2d4605b8608                   []   \n",
       "9c433729-bb55-4cac-92f2-00903434fa28                   []   \n",
       "0caee60d-567c-4f74-b0e0-aa4efe189ead                   []   \n",
       "\n",
       "                                                                               metadata  \n",
       "id                                                                                       \n",
       "f7688518-56c0-42b6-ac14-a3c83992a93d  {'question_type': 'simple', 'seed_document_id'...  \n",
       "aa5a916d-be2a-43bd-beee-3d778333d784  {'question_type': 'simple', 'seed_document_id'...  \n",
       "d58efa9b-2a56-4211-969b-c2d4605b8608  {'question_type': 'simple', 'seed_document_id'...  \n",
       "9c433729-bb55-4cac-92f2-00903434fa28  {'question_type': 'simple', 'seed_document_id'...  \n",
       "0caee60d-567c-4f74-b0e0-aa4efe189ead  {'question_type': 'simple', 'seed_document_id'...  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset_df = testset.to_pandas()\n",
    "testset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_df.to_excel(\"testset250.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate gkiskard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking questions to the agent:   0%|          | 0/45 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[214], line 68\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cm\n\u001b[1;32m     67\u001b[0m giskard\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mset_default_client(TesterLLM())\n\u001b[0;32m---> 68\u001b[0m report \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_answer_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtestset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknowledge_base\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mknowledge_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTesterLLM\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/evaluate.py:79\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(answer_fn, testset, knowledge_base, llm_client, agent_description, metrics)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m testset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     testset \u001b[38;5;241m=\u001b[39m generate_testset(knowledge_base)\n\u001b[1;32m     76\u001b[0m model_outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     77\u001b[0m     [_cast_to_agent_answer(ans) \u001b[38;5;28;01mfor\u001b[39;00m ans \u001b[38;5;129;01min\u001b[39;00m answer_fn]\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(answer_fn, Sequence)\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_compute_answers\u001b[49m\u001b[43m(\u001b[49m\u001b[43manswer_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m )\n\u001b[1;32m     82\u001b[0m llm_client \u001b[38;5;241m=\u001b[39m llm_client \u001b[38;5;129;01mor\u001b[39;00m get_default_client()\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# @TODO: improve this\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/giskard/rag/evaluate.py:141\u001b[0m, in \u001b[0;36m_compute_answers\u001b[0;34m(answer_fn, testset)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m needs_history:\n\u001b[1;32m    139\u001b[0m         kwargs[ANSWER_FN_HISTORY_PARAM] \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mconversation_history\n\u001b[0;32m--> 141\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[43manswer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     model_outputs\u001b[38;5;241m.\u001b[39mappend(_cast_to_agent_answer(answer))\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_outputs\n",
      "Cell \u001b[0;32mIn[214], line 25\u001b[0m, in \u001b[0;36mget_answer_fn\u001b[0;34m(question, history)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m content\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m retrieval_type\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_marginal_relevance\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 25\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[43mvector_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_marginal_relevance_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, doc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(docs):\n",
      "File \u001b[0;32m~/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/langchain_core/vectorstores/in_memory.py:459\u001b[0m, in \u001b[0;36mInMemoryVectorStore.max_marginal_relevance_search\u001b[0;34m(self, query, k, fetch_k, lambda_mult, **kwargs)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax_marginal_relevance_search\u001b[39m(\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    453\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    458\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[0;32m--> 459\u001b[0m     embedding_vector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_marginal_relevance_search_by_vector(\n\u001b[1;32m    461\u001b[0m         embedding_vector,\n\u001b[1;32m    462\u001b[0m         k,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    466\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/langchain_openai/embeddings/base.py:629\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21membed_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    621\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call out to OpenAI's embedding endpoint for embedding query text.\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \n\u001b[1;32m    623\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;124;03m        Embedding for the text.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/langchain_openai/embeddings/base.py:588\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[0;34m(self, texts, chunk_size)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[1;32m    587\u001b[0m engine \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment)\n\u001b[0;32m--> 588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/langchain_openai/embeddings/base.py:483\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[0;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[1;32m    481\u001b[0m batched_embeddings: List[List[\u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[0;32m--> 483\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_chunk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invocation_params\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    487\u001b[0m         response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mmodel_dump()\n",
      "File \u001b[0;32m~/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/resources/embeddings.py:124\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[0;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    118\u001b[0m         embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[1;32m    119\u001b[0m             base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py:1277\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1265\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1272\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1274\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1275\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1276\u001b[0m     )\n\u001b[0;32m-> 1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py:954\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    952\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 954\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py:1043\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1042\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1043\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py:1092\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1092\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py:1043\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1042\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1043\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py:1092\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1092\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/SynTag/syntag/misc/agents/umd-call-center/.venv/lib/python3.12/site-packages/openai/_base_client.py:1058\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1055\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1057\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1061\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1062\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1066\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1067\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "from typing import Literal, Sequence\n",
    "from giskard.llm.client.base import ChatMessage\n",
    "from giskard.rag import evaluate\n",
    "import openai\n",
    "\n",
    "prompt_type: Literal[\"api\", \"p1\"] = \"p1\"\n",
    "retrieval_type: Literal[\"similarity_search\", \"max_marginal_relevance\"] = \"max_marginal_relevance\"\n",
    "retrieval_meta: Literal[\"top3\", \"top5\", \"top10\"] = \"top5\"\n",
    "\n",
    "def get_answer_fn(question: str, history=None) -> str:\n",
    "    \"\"\"A function representing your RAG agent.\"\"\"\n",
    "    # Format appropriately the history for your RAG agent\n",
    "    messages = history if history else []\n",
    "    messages.append({\"role\": \"user\", \"content\": question})\n",
    "\n",
    "\n",
    "    if retrieval_type==\"similarity_search\":\n",
    "        similarity_search_with_score = vector_store.similarity_search_with_score(question, k=5)\n",
    "        content=\"\"\n",
    "        for i, doc_score in enumerate(similarity_search_with_score):\n",
    "            doc, score = doc_score\n",
    "            content += f\"Source {i}. Relevency Score: {score}:\\n\"+ doc.page_content + \"\\n\\n\"\n",
    "        return content\n",
    "    elif retrieval_type==\"max_marginal_relevance\":\n",
    "        docs = vector_store.max_marginal_relevance_search(question, k=5)\n",
    "        content = \"\"\n",
    "        for i, doc in enumerate(docs):\n",
    "            content += f\"Source {i}:\\n\"+ doc.page_content + \"\\n\\n\"\n",
    "        return content\n",
    "\n",
    "    if prompt_type == \"api\":\n",
    "        system_message = \"Search results found the following information that might be relevent:\\n\\n\" \n",
    "\n",
    "        messages.append({\"role\": \"system\", \"content\": system_message + sources_str})\n",
    "\n",
    "        reminder_message = \"Remember, you are on a phone call. Your response to the caller should be accurate and concise. Do not monologue. Here is the caller's message:\"\n",
    "        messages.append({\"role\": \"system\", \"content\": reminder_message})\n",
    "    elif prompt_type == \"p1\":\n",
    "        system_message = \"Search results found the following information that might be relevent:\\n\\n\" \n",
    "        messages.append({\"role\": \"system\", \"content\": system_message + sources_str})\n",
    "\n",
    "        instructions = \"You are helpful support agent who answers phone calls.\\n Search results will be given to you to help you answer questions. Only use those results to answer questions. If a topic comes up that you don't know, do not answer. You are to concisely answer their question, instead of quoting the information.Never insert additional information. If something is unclear, ask for clarification.\"\n",
    "        messages.insert(0, {\"role\": \"system\", \"content\": instructions})\n",
    "        messages.append({\"role\": \"system\", \"content\": instructions})\n",
    "\n",
    "    chatcompletion = openai.chat.completions.create(messages=messages, model=\"gpt-4o-mini\")\n",
    "    answer = chatcompletion.choices[0].message.content\n",
    "    return answer\n",
    "\n",
    "\n",
    "#ragas_context_recall = RagasMetric(name=\"RAGAS Context Recall\", metric=context_recall, requires_context=True)\n",
    "\n",
    "from giskard.llm.client import LLMClient\n",
    "from openai.types.chat.completion_create_params import ResponseFormatJSONObject, ResponseFormatText\n",
    "test_llm: Literal[None, \"gpt-4o-mini\"] = \"gpt-4o-mini\"\n",
    "class TesterLLM(LLMClient):\n",
    "    def complete(self, messages: Sequence[ChatMessage], temperature: float = 1, max_tokens: int | None = None, caller_id: str | None = None, seed: int | None = None, format=None) -> ChatMessage:\n",
    "        messages_openai = [{\"role\": message.role, \"content\": message.content} for message in messages]\n",
    "        if format is not None and \"json\" in format:\n",
    "            rformat: ResponseFormatJSONObject = {\"type\": \"json_object\"}\n",
    "        else:\n",
    "            rformat: ResponseFormatText = {\"type\": \"text\"}\n",
    "        response = openai.chat.completions.create(messages=messages_openai, model=\"gpt-4o-mini\", temperature=temperature, max_tokens=max_tokens, seed=seed, response_format=rformat)\n",
    "        \n",
    "        cm = ChatMessage(role=response.choices[0].message.role, content=response.choices[0].message.content)\n",
    "        return cm\n",
    "giskard.llm.set_default_client(TesterLLM())\n",
    "report = evaluate(get_answer_fn, testset=testset, knowledge_base=knowledge_base, llm_client=TesterLLM())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(report)  # if you are working in a notebook\n",
    "\n",
    "# or save the report as an HTML file\n",
    "#report.to_html(\"rag_eval_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.save(f\"reports_testset45-o1preview/{prompt_type}-gpt_4o_mini-splits_character-{retrieval_type}-{retrieval_meta}-zerox-tester_{test_llm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from giskard.rag import RAGReport\n",
    "loaded_report = RAGReport.load(\"reports/...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<giskard.rag.knowledge_base.KnowledgeBase at 0x341418ce0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report._knowledge_base._to_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>reference_context</th>\n",
       "      <th>conversation_history</th>\n",
       "      <th>metadata</th>\n",
       "      <th>agent_answer</th>\n",
       "      <th>correctness</th>\n",
       "      <th>correctness_reason</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9c63fed4-b956-4aa0-9501-741321f4f034</th>\n",
       "      <td>What happens if a student does not work throug...</td>\n",
       "      <td>If a student does not work through Labor Day, ...</td>\n",
       "      <td>Document 147: summer benefits\\nSummer housing ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'simple', 'seed_document_id'...</td>\n",
       "      <td>If a student living in summer housing does not...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent provided a general response about im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f29be739-0393-44a5-a519-7912dba4c9e1</th>\n",
       "      <td>What should a staff member do if they are goin...</td>\n",
       "      <td>They are expected to immediately call the Serv...</td>\n",
       "      <td>Document 45: If a staff member is unable to re...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'simple', 'seed_document_id'...</td>\n",
       "      <td>If a staff member knows they will be late for ...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent provided a general response about no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb530e2e-e211-41f1-9c11-3e5bc8078666</th>\n",
       "      <td>In order to be considered for a promotion to t...</td>\n",
       "      <td>An employee must work a minimum of 120 total h...</td>\n",
       "      <td>Document 135: a. Possess a satisfactory perfor...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'complex', 'seed_document_id...</td>\n",
       "      <td>The minimum total number of hours an employee ...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent did not provide the specific minimum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c9e0790a-3be2-4adf-b9bd-7de3f0c01105</th>\n",
       "      <td>Could you specify the individuals who hold the...</td>\n",
       "      <td>Only the Service Center Assistant Manager, Man...</td>\n",
       "      <td>Document 162: All keys, swipes and key rings i...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'complex', 'seed_document_id...</td>\n",
       "      <td>The authority to approve the signing out of ke...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent provided a broader list of roles tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94e282d7-352b-42f9-b78e-762e24a61c1d</th>\n",
       "      <td>What steps should a student take regarding the...</td>\n",
       "      <td>If you have a student parking permit, remove i...</td>\n",
       "      <td>Document 55: If you have a student parking per...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'distracting element', 'seed...</td>\n",
       "      <td>If a student has received a written warning fo...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent provided a detailed response about g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e049d396-2658-4b2f-8722-e42697cdc731</th>\n",
       "      <td>In the event that a substitute fails to report...</td>\n",
       "      <td>The original (scheduled/assigned) staff member...</td>\n",
       "      <td>Document 48: If the substitute does not report...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'distracting element', 'seed...</td>\n",
       "      <td>When a substitute fails to report for their sc...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent provided a detailed response about t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14060525-e7cd-4fa3-b239-501a78dc994c</th>\n",
       "      <td>Hi, I'm a staff member at the university and I...</td>\n",
       "      <td>The driver should take the vehicle out to Moto...</td>\n",
       "      <td>Document 171: Vehicles should never be returne...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'situational', 'seed_documen...</td>\n",
       "      <td>It's important to ensure that university vehic...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent provided general refueling procedure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42d9bf93-4e26-4fef-b301-c31e7cd69bd8</th>\n",
       "      <td>Hi there, I’m currently dealing with an unexpe...</td>\n",
       "      <td>If a staff member is not able to safely travel...</td>\n",
       "      <td>Document 63: In the event the University has a...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'situational', 'seed_documen...</td>\n",
       "      <td>If you are a staff member unable to safely tra...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent provided a detailed response about g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ad2c7d12-7bb1-4710-9efc-16f83d2bbbeb</th>\n",
       "      <td>What is the main purpose of the Service Center...</td>\n",
       "      <td>The Service Center serves as the main communic...</td>\n",
       "      <td>Document 6: The Department of Residential Faci...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'double', 'original_question...</td>\n",
       "      <td>The main purpose of the Service Center is to p...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent provided a general description of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dc21b28c-3d62-4a84-83fc-ba8b83599849</th>\n",
       "      <td>What are the consequences?</td>\n",
       "      <td>Forgetting ID when working and using key slip ...</td>\n",
       "      <td>Document 182: not completing work in the box o...</td>\n",
       "      <td>[{'role': 'user', 'content': 'I want to know w...</td>\n",
       "      <td>{'question_type': 'conversational', 'seed_docu...</td>\n",
       "      <td>The consequences of an employee forgetting the...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent provided a detailed explanation of p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                               question  \\\n",
       "id                                                                                        \n",
       "9c63fed4-b956-4aa0-9501-741321f4f034  What happens if a student does not work throug...   \n",
       "f29be739-0393-44a5-a519-7912dba4c9e1  What should a staff member do if they are goin...   \n",
       "fb530e2e-e211-41f1-9c11-3e5bc8078666  In order to be considered for a promotion to t...   \n",
       "c9e0790a-3be2-4adf-b9bd-7de3f0c01105  Could you specify the individuals who hold the...   \n",
       "94e282d7-352b-42f9-b78e-762e24a61c1d  What steps should a student take regarding the...   \n",
       "e049d396-2658-4b2f-8722-e42697cdc731  In the event that a substitute fails to report...   \n",
       "14060525-e7cd-4fa3-b239-501a78dc994c  Hi, I'm a staff member at the university and I...   \n",
       "42d9bf93-4e26-4fef-b301-c31e7cd69bd8  Hi there, I’m currently dealing with an unexpe...   \n",
       "ad2c7d12-7bb1-4710-9efc-16f83d2bbbeb  What is the main purpose of the Service Center...   \n",
       "dc21b28c-3d62-4a84-83fc-ba8b83599849                         What are the consequences?   \n",
       "\n",
       "                                                                       reference_answer  \\\n",
       "id                                                                                        \n",
       "9c63fed4-b956-4aa0-9501-741321f4f034  If a student does not work through Labor Day, ...   \n",
       "f29be739-0393-44a5-a519-7912dba4c9e1  They are expected to immediately call the Serv...   \n",
       "fb530e2e-e211-41f1-9c11-3e5bc8078666  An employee must work a minimum of 120 total h...   \n",
       "c9e0790a-3be2-4adf-b9bd-7de3f0c01105  Only the Service Center Assistant Manager, Man...   \n",
       "94e282d7-352b-42f9-b78e-762e24a61c1d  If you have a student parking permit, remove i...   \n",
       "e049d396-2658-4b2f-8722-e42697cdc731  The original (scheduled/assigned) staff member...   \n",
       "14060525-e7cd-4fa3-b239-501a78dc994c  The driver should take the vehicle out to Moto...   \n",
       "42d9bf93-4e26-4fef-b301-c31e7cd69bd8  If a staff member is not able to safely travel...   \n",
       "ad2c7d12-7bb1-4710-9efc-16f83d2bbbeb  The Service Center serves as the main communic...   \n",
       "dc21b28c-3d62-4a84-83fc-ba8b83599849  Forgetting ID when working and using key slip ...   \n",
       "\n",
       "                                                                      reference_context  \\\n",
       "id                                                                                        \n",
       "9c63fed4-b956-4aa0-9501-741321f4f034  Document 147: summer benefits\\nSummer housing ...   \n",
       "f29be739-0393-44a5-a519-7912dba4c9e1  Document 45: If a staff member is unable to re...   \n",
       "fb530e2e-e211-41f1-9c11-3e5bc8078666  Document 135: a. Possess a satisfactory perfor...   \n",
       "c9e0790a-3be2-4adf-b9bd-7de3f0c01105  Document 162: All keys, swipes and key rings i...   \n",
       "94e282d7-352b-42f9-b78e-762e24a61c1d  Document 55: If you have a student parking per...   \n",
       "e049d396-2658-4b2f-8722-e42697cdc731  Document 48: If the substitute does not report...   \n",
       "14060525-e7cd-4fa3-b239-501a78dc994c  Document 171: Vehicles should never be returne...   \n",
       "42d9bf93-4e26-4fef-b301-c31e7cd69bd8  Document 63: In the event the University has a...   \n",
       "ad2c7d12-7bb1-4710-9efc-16f83d2bbbeb  Document 6: The Department of Residential Faci...   \n",
       "dc21b28c-3d62-4a84-83fc-ba8b83599849  Document 182: not completing work in the box o...   \n",
       "\n",
       "                                                                   conversation_history  \\\n",
       "id                                                                                        \n",
       "9c63fed4-b956-4aa0-9501-741321f4f034                                                 []   \n",
       "f29be739-0393-44a5-a519-7912dba4c9e1                                                 []   \n",
       "fb530e2e-e211-41f1-9c11-3e5bc8078666                                                 []   \n",
       "c9e0790a-3be2-4adf-b9bd-7de3f0c01105                                                 []   \n",
       "94e282d7-352b-42f9-b78e-762e24a61c1d                                                 []   \n",
       "e049d396-2658-4b2f-8722-e42697cdc731                                                 []   \n",
       "14060525-e7cd-4fa3-b239-501a78dc994c                                                 []   \n",
       "42d9bf93-4e26-4fef-b301-c31e7cd69bd8                                                 []   \n",
       "ad2c7d12-7bb1-4710-9efc-16f83d2bbbeb                                                 []   \n",
       "dc21b28c-3d62-4a84-83fc-ba8b83599849  [{'role': 'user', 'content': 'I want to know w...   \n",
       "\n",
       "                                                                               metadata  \\\n",
       "id                                                                                        \n",
       "9c63fed4-b956-4aa0-9501-741321f4f034  {'question_type': 'simple', 'seed_document_id'...   \n",
       "f29be739-0393-44a5-a519-7912dba4c9e1  {'question_type': 'simple', 'seed_document_id'...   \n",
       "fb530e2e-e211-41f1-9c11-3e5bc8078666  {'question_type': 'complex', 'seed_document_id...   \n",
       "c9e0790a-3be2-4adf-b9bd-7de3f0c01105  {'question_type': 'complex', 'seed_document_id...   \n",
       "94e282d7-352b-42f9-b78e-762e24a61c1d  {'question_type': 'distracting element', 'seed...   \n",
       "e049d396-2658-4b2f-8722-e42697cdc731  {'question_type': 'distracting element', 'seed...   \n",
       "14060525-e7cd-4fa3-b239-501a78dc994c  {'question_type': 'situational', 'seed_documen...   \n",
       "42d9bf93-4e26-4fef-b301-c31e7cd69bd8  {'question_type': 'situational', 'seed_documen...   \n",
       "ad2c7d12-7bb1-4710-9efc-16f83d2bbbeb  {'question_type': 'double', 'original_question...   \n",
       "dc21b28c-3d62-4a84-83fc-ba8b83599849  {'question_type': 'conversational', 'seed_docu...   \n",
       "\n",
       "                                                                           agent_answer  \\\n",
       "id                                                                                        \n",
       "9c63fed4-b956-4aa0-9501-741321f4f034  If a student living in summer housing does not...   \n",
       "f29be739-0393-44a5-a519-7912dba4c9e1  If a staff member knows they will be late for ...   \n",
       "fb530e2e-e211-41f1-9c11-3e5bc8078666  The minimum total number of hours an employee ...   \n",
       "c9e0790a-3be2-4adf-b9bd-7de3f0c01105  The authority to approve the signing out of ke...   \n",
       "94e282d7-352b-42f9-b78e-762e24a61c1d  If a student has received a written warning fo...   \n",
       "e049d396-2658-4b2f-8722-e42697cdc731  When a substitute fails to report for their sc...   \n",
       "14060525-e7cd-4fa3-b239-501a78dc994c  It's important to ensure that university vehic...   \n",
       "42d9bf93-4e26-4fef-b301-c31e7cd69bd8  If you are a staff member unable to safely tra...   \n",
       "ad2c7d12-7bb1-4710-9efc-16f83d2bbbeb  The main purpose of the Service Center is to p...   \n",
       "dc21b28c-3d62-4a84-83fc-ba8b83599849  The consequences of an employee forgetting the...   \n",
       "\n",
       "                                      correctness  \\\n",
       "id                                                  \n",
       "9c63fed4-b956-4aa0-9501-741321f4f034        False   \n",
       "f29be739-0393-44a5-a519-7912dba4c9e1        False   \n",
       "fb530e2e-e211-41f1-9c11-3e5bc8078666        False   \n",
       "c9e0790a-3be2-4adf-b9bd-7de3f0c01105        False   \n",
       "94e282d7-352b-42f9-b78e-762e24a61c1d        False   \n",
       "e049d396-2658-4b2f-8722-e42697cdc731        False   \n",
       "14060525-e7cd-4fa3-b239-501a78dc994c        False   \n",
       "42d9bf93-4e26-4fef-b301-c31e7cd69bd8        False   \n",
       "ad2c7d12-7bb1-4710-9efc-16f83d2bbbeb        False   \n",
       "dc21b28c-3d62-4a84-83fc-ba8b83599849        False   \n",
       "\n",
       "                                                                     correctness_reason  \n",
       "id                                                                                       \n",
       "9c63fed4-b956-4aa0-9501-741321f4f034  The agent provided a general response about im...  \n",
       "f29be739-0393-44a5-a519-7912dba4c9e1  The agent provided a general response about no...  \n",
       "fb530e2e-e211-41f1-9c11-3e5bc8078666  The agent did not provide the specific minimum...  \n",
       "c9e0790a-3be2-4adf-b9bd-7de3f0c01105  The agent provided a broader list of roles tha...  \n",
       "94e282d7-352b-42f9-b78e-762e24a61c1d  The agent provided a detailed response about g...  \n",
       "e049d396-2658-4b2f-8722-e42697cdc731  The agent provided a detailed response about t...  \n",
       "14060525-e7cd-4fa3-b239-501a78dc994c  The agent provided general refueling procedure...  \n",
       "42d9bf93-4e26-4fef-b301-c31e7cd69bd8  The agent provided a detailed response about g...  \n",
       "ad2c7d12-7bb1-4710-9efc-16f83d2bbbeb  The agent provided a general description of th...  \n",
       "dc21b28c-3d62-4a84-83fc-ba8b83599849  The agent provided a detailed explanation of p...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report.failures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone.grpc import GRPCVector\n",
    "from pinecone.grpc.index_grpc import UpsertResponse\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_HOST = os.getenv(\"PINECONE_HOST\")\n",
    "PINECONE_NAMESPACE = \"umd-call-center\"\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "PC_INDEX_NAME = \"knowledge\"\n",
    "pc_index = pc.Index(PC_INDEX_NAME, host=PINECONE_HOST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def query_pc(vector: List[float]):\n",
    "    query_result = pc_index.query(\n",
    "        vector=vector,\n",
    "        namespace=PINECONE_NAMESPACE,\n",
    "        top_k=10,\n",
    "        #filter={\"knowledge_uuid\": {\"$in\": knowledge_uuids}},\n",
    "        include_metadata=True,\n",
    "        timeout=1,\n",
    "    )\n",
    "    return query_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    # Compute dot product\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    # Compute magnitudes\n",
    "    magnitude_vec1 = np.linalg.norm(vec1)\n",
    "    magnitude_vec2 = np.linalg.norm(vec2)\n",
    "    # Calculate cosine similarity\n",
    "    if magnitude_vec1 == 0 or magnitude_vec2 == 0:\n",
    "        return 0  # Handle the case of zero magnitude\n",
    "    return dot_product / (magnitude_vec1 * magnitude_vec2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
